# Senior DevOps Engineer Interview Preparation
## Complete Three-Tier Question Bank

---

# TABLE OF CONTENTS

**BASIC LEVEL (Q1-Q10)**
- Docker Fundamentals
- Kubernetes Basics
- Ansible Basics
- Linux & Scripting
- GitHub Basics

**INTERMEDIATE LEVEL (Q11-Q20)**
- Docker Advanced
- Kubernetes Intermediate
- Ansible Roles & Automation
- GitHub Actions & CI/CD

**HARDCORE LEVEL (Q21-Q30)**
- Production Scenarios
- Architecture & Design
- Troubleshooting Complex Issues
- Security & Compliance
- Performance Optimization

---

# INTERMEDIATE LEVEL QUESTIONS (Continued)

## 2.3 Kubernetes StatefulSets

**Q14: Explain the difference between Deployment and StatefulSet. When would you use StatefulSet?**

**Answer:**
"Deployments and StatefulSets both manage pods, but serve different purposes.

**Key Differences:**

| Aspect | Deployment | StatefulSet |
|--------|------------|-------------|
| Pod Identity | Random names (pod-abc123) | Ordered names (pod-0, pod-1) |
| Pod Replacement | Can replace with any pod | Must replace with same identity |
| Storage | Shared or independent | Dedicated persistent storage per pod |
| Startup Order | Parallel | Sequential (0â†’1â†’2) |
| Network Identity | Dynamic IP | Stable hostname |
| Use Case | Stateless apps | Stateful apps (databases) |

**Deployment Example (Stateless):**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.24
        ports:
        - containerPort: 80

# Creates pods:
# nginx-deployment-abc123
# nginx-deployment-def456
# nginx-deployment-ghi789
# Order doesn't matter, names are random
```

**StatefulSet Example (Stateful):**
```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres-service  # Headless service required
  replicas: 3
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:14
        ports:
        - containerPort: 5432
        volumeMounts:
        - name: data
          mountPath: /var/lib/postgresql/data
  volumeClaimTemplates:  # Each pod gets its own PVC
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 10Gi

# Creates pods in order:
# postgres-0 (waits for ready before creating next)
# postgres-1
# postgres-2

# Each pod has:
# - Stable hostname: postgres-0.postgres-service
# - Dedicated storage: data-postgres-0, data-postgres-1, data-postgres-2
```

**When to use StatefulSet:**

**Use StatefulSet for:**
âœ… Databases (PostgreSQL, MySQL, MongoDB)
âœ… Distributed systems (Kafka, Zookeeper, Cassandra)
âœ… Applications requiring stable network identity
âœ… Applications requiring ordered deployment/scaling
âœ… Applications with persistent data tied to pod identity

**Use Deployment for:**
âœ… Web servers (Nginx, Apache)
âœ… APIs and microservices
âœ… Stateless applications
âœ… Applications that can handle pod recreation

**Real Example - MySQL Primary-Replica:**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: mysql
  labels:
    app: mysql
spec:
  ports:
  - port: 3306
  clusterIP: None  # Headless service
  selector:
    app: mysql
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
spec:
  serviceName: mysql
  replicas: 3
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - name: mysql
        image: mysql:8.0
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: password
        ports:
        - containerPort: 3306
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
        - name: config
          mountPath: /etc/mysql/conf.d
      volumes:
      - name: config
        configMap:
          name: mysql-config
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 20Gi
```

**Access patterns:**
```bash
# Access specific pod
mysql -h mysql-0.mysql -u root -p

# Access any pod (via service)
mysql -h mysql -u root -p

# DNS names are predictable
mysql-0.mysql.default.svc.cluster.local
mysql-1.mysql.default.svc.cluster.local
mysql-2.mysql.default.svc.cluster.local
```

**Scaling behavior:**

**Deployment:**
```bash
kubectl scale deployment nginx --replicas=5
# Quickly creates 2 new pods with random names
# New pods: nginx-deployment-xyz123, nginx-deployment-abc456
```

**StatefulSet:**
```bash
kubectl scale statefulset mysql --replicas=5
# Creates pods sequentially
# mysql-3 (waits for ready)
# mysql-4 (waits for mysql-3 ready)
```

**Key StatefulSet Features:**

**1. Stable Network Identity:**
```yaml
# Each pod gets predictable hostname
Pod: postgres-0
Hostname: postgres-0.postgres-service.default.svc.cluster.local
```

**2. Stable Storage:**
```yaml
# Storage persists even if pod is deleted
# When postgres-0 is recreated, it gets same PVC: data-postgres-0
```

**3. Ordered Operations:**
```yaml
Deployment (scale up 1â†’3):
  Creates all pods simultaneously
  â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
  â”‚ P0  â”‚ P1  â”‚ P2  â”‚
  â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
  All start at once

StatefulSet (scale up 1â†’3):
  Creates pods in order
  P0 â†’ (ready) â†’ P1 â†’ (ready) â†’ P2
```

**Comparison Summary:**

**Scenario:** Running a web application with 3 replicas

**With Deployment:**
```
Pros:
âœ“ Fast scaling
âœ“ Simple configuration
âœ“ Good for stateless apps
âœ“ Easy rolling updates

Cons:
âœ— No stable identity
âœ— Shared storage only
âœ— Random pod names
```

**With StatefulSet:**
```
Pros:
âœ“ Stable pod names
âœ“ Dedicated storage per pod
âœ“ Predictable network identity
âœ“ Ordered operations

Cons:
âœ— Slower scaling
âœ— More complex
âœ— Overkill for stateless apps
```

**In my experience at Birlasoft:**
- Used Deployments for: APIs, web servers, workers (90% of workloads)
- Used StatefulSets for: Databases, message brokers, monitoring (10% of workloads)

**Rule of thumb:** Default to Deployment, use StatefulSet only when you need stable identity and dedicated storage."

---

## 2.4 Ansible Roles

**Q15: Create an Ansible role to install and configure Nginx with custom templates. Show the directory structure and key files.**

**Answer:**
"Ansible roles organize playbooks into reusable, structured components.

**Role Directory Structure:**

```
roles/
â””â”€â”€ nginx/
    â”œâ”€â”€ README.md
    â”œâ”€â”€ defaults/
    â”‚   â””â”€â”€ main.yml
    â”œâ”€â”€ files/
    â”‚   â””â”€â”€ index.html
    â”œâ”€â”€ handlers/
    â”‚   â””â”€â”€ main.yml
    â”œâ”€â”€ meta/
    â”‚   â””â”€â”€ main.yml
    â”œâ”€â”€ tasks/
    â”‚   â””â”€â”€ main.yml
    â”œâ”€â”€ templates/
    â”‚   â”œâ”€â”€ nginx.conf.j2
    â”‚   â””â”€â”€ site.conf.j2
    â”œâ”€â”€ tests/
    â”‚   â”œâ”€â”€ inventory
    â”‚   â””â”€â”€ test.yml
    â””â”€â”€ vars/
        â””â”€â”€ main.yml
```

**Create role structure:**
```bash
# Initialize role
ansible-galaxy init roles/nginx

# Or manually create structure
mkdir -p roles/nginx/{defaults,files,handlers,meta,tasks,templates,vars}
```

**1. defaults/main.yml (Default Variables):**
```yaml
---
# Default variables (lowest precedence - can be overridden)
nginx_port: 80
nginx_user: nginx
nginx_worker_processes: auto
nginx_worker_connections: 1024
nginx_keepalive_timeout: 65

nginx_sites:
  - name: default
    server_name: localhost
    root: /var/www/html
    index: index.html

nginx_remove_default_site: true
nginx_enable_ssl: false
```

**2. vars/main.yml (Role Variables):**
```yaml
---
# Variables specific to this role (higher precedence)
nginx_package_name: nginx
nginx_service_name: nginx
nginx_conf_dir: /etc/nginx
nginx_log_dir: /var/log/nginx
```

**3. tasks/main.yml (Main Tasks):**
```yaml
---
- name: Include OS-specific variables
  include_vars: "{{ ansible_os_family }}.yml"

- name: Install Nginx
  package:
    name: "{{ nginx_package_name }}"
    state: present
  tags: install

- name: Create required directories
  file:
    path: "{{ item }}"
    state: directory
    owner: "{{ nginx_user }}"
    group: "{{ nginx_user }}"
    mode: '0755'
  loop:
    - "{{ nginx_conf_dir }}/sites-available"
    - "{{ nginx_conf_dir }}/sites-enabled"
    - "{{ nginx_log_dir }}"
  tags: config

- name: Deploy main nginx configuration
  template:
    src: nginx.conf.j2
    dest: "{{ nginx_conf_dir }}/nginx.conf"
    owner: root
    group: root
    mode: '0644'
    validate: 'nginx -t -c %s'
  notify: reload nginx
  tags: config

- name: Remove default site if requested
  file:
    path: "{{ nginx_conf_dir }}/sites-enabled/default"
    state: absent
  when: nginx_remove_default_site
  notify: reload nginx
  tags: config

- name: Deploy site configurations
  template:
    src: site.conf.j2
    dest: "{{ nginx_conf_dir }}/sites-available/{{ item.name }}"
    owner: root
    group: root
    mode: '0644'
  loop: "{{ nginx_sites }}"
  notify: reload nginx
  tags: config

- name: Enable sites
  file:
    src: "{{ nginx_conf_dir }}/sites-available/{{ item.name }}"
    dest: "{{ nginx_conf_dir }}/sites-enabled/{{ item.name }}"
    state: link
  loop: "{{ nginx_sites }}"
  notify: reload nginx
  tags: config

- name: Deploy custom index.html
  copy:
    src: index.html
    dest: /var/www/html/index.html
    owner: "{{ nginx_user }}"
    group: "{{ nginx_user }}"
    mode: '0644'
  tags: content

- name: Start and enable Nginx
  service:
    name: "{{ nginx_service_name }}"
    state: started
    enabled: yes
  tags: service

- name: Configure firewall
  firewalld:
    service: "{{ item }}"
    permanent: yes
    state: enabled
    immediate: yes
  loop:
    - http
    - https
  when: ansible_os_family == "RedHat"
  tags: firewall
```

**4. templates/nginx.conf.j2:**
```jinja2
user {{ nginx_user }};
worker_processes {{ nginx_worker_processes }};
error_log {{ nginx_log_dir }}/error.log;
pid /run/nginx.pid;

events {
    worker_connections {{ nginx_worker_connections }};
}

http {
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log {{ nginx_log_dir }}/access.log main;

    sendfile            on;
    tcp_nopush          on;
    tcp_nodelay         on;
    keepalive_timeout   {{ nginx_keepalive_timeout }};
    types_hash_max_size 2048;

    include             /etc/nginx/mime.types;
    default_type        application/octet-stream;

    # Include site configurations
    include {{ nginx_conf_dir }}/sites-enabled/*;
}
```

**5. templates/site.conf.j2:**
```jinja2
server {
    listen {{ nginx_port }};
    server_name {{ item.server_name }};
    
    root {{ item.root }};
    index {{ item.index }};
    
    access_log {{ nginx_log_dir }}/{{ item.name }}-access.log;
    error_log {{ nginx_log_dir }}/{{ item.name }}-error.log;
    
    location / {
        try_files $uri $uri/ =404;
    }
    
{% if nginx_enable_ssl %}
    listen 443 ssl;
    ssl_certificate {{ nginx_conf_dir }}/ssl/{{ item.name }}.crt;
    ssl_certificate_key {{ nginx_conf_dir }}/ssl/{{ item.name }}.key;
{% endif %}
}
```

**6. handlers/main.yml:**
```yaml
---
- name: reload nginx
  service:
    name: "{{ nginx_service_name }}"
    state: reloaded

- name: restart nginx
  service:
    name: "{{ nginx_service_name }}"
    state: restarted
```

**7. files/index.html:**
```html
<!DOCTYPE html>
<html>
<head>
    <title>Welcome to Nginx</title>
</head>
<body>
    <h1>Server deployed with Ansible</h1>
    <p>This page was deployed using Ansible roles.</p>
</body>
</html>
```

**8. meta/main.yml:**
```yaml
---
galaxy_info:
  author: DevOps Team
  description: Nginx web server installation and configuration
  company: Your Company
  license: MIT
  min_ansible_version: 2.9
  platforms:
    - name: EL
      versions:
        - 7
        - 8
    - name: Ubuntu
      versions:
        - 18.04
        - 20.04
  galaxy_tags:
    - nginx
    - webserver

dependencies: []
  # Example: depends on firewall role
  # - role: firewall
  #   when: configure_firewall
```

**Using the Role:**

**Playbook:**
```yaml
# site.yml
---
- name: Setup web servers
  hosts: webservers
  become: yes
  
  roles:
    - role: nginx
      vars:
        nginx_port: 8080
        nginx_sites:
          - name: myapp
            server_name: app.example.com
            root: /var/www/myapp
            index: index.html
          - name: api
            server_name: api.example.com
            root: /var/www/api
            index: index.html
```

**Run:**
```bash
# Install role from Galaxy
ansible-galaxy install -r requirements.yml

# Run playbook
ansible-playbook -i inventory/production.ini site.yml

# Run with tags
ansible-playbook -i inventory/production.ini site.yml --tags config

# Check mode (dry run)
ansible-playbook -i inventory/production.ini site.yml --check
```

**requirements.yml (for sharing):**
```yaml
---
# External roles
- src: geerlingguy.nginx
  version: 3.1.4

# Local roles
- src: roles/nginx
  name: nginx
```

**Testing the Role:**
```yaml
# tests/test.yml
---
- hosts: localhost
  remote_user: root
  roles:
    - nginx
```

**Role Benefits:**
- **Reusable**: Use across projects
- **Shareable**: Ansible Galaxy
- **Testable**: Molecule framework
- **Organized**: Clear structure
- **Maintainable**: Separation of concerns

This is production-ready and follows Ansible best practices!"

---

## 2.5 GitHub Actions

**Q16: Create a GitHub Actions workflow for a Node.js application that builds, tests, creates Docker image, and deploys to Kubernetes.**

**Answer:**

**Complete CI/CD Workflow:**

```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  NODE_VERSION: '18'
  DOCKER_REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  
jobs:
  # Job 1: Build and Test
  build-and-test:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Run linter
      run: npm run lint
    
    - name: Run unit tests
      run: npm test -- --coverage
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        files: ./coverage/lcov.info
    
    - name: Build application
      run: npm run build
    
    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      with:
        name: build
        path: dist/
        retention-days: 1

  # Job 2: Security Scan
  security-scan:
    runs-on: ubuntu-latest
    needs: build-and-test
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Run Snyk security scan
      uses: snyk/actions/node@master
      env:
        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
      with:
        args: --severity-threshold=high
    
    - name: Run npm audit
      run: npm audit --audit-level=high
      continue-on-error: true

  # Job 3: Build Docker Image
  build-docker:
    runs-on: ubuntu-latest
    needs: [build-and-test, security-scan]
    if: github.event_name == 'push'
    
    permissions:
      contents: read
      packages: write
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Login to GitHub Container Registry
      uses: docker/login-action@v2
      with:
        registry: ${{ env.DOCKER_REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v4
      with:
        images: ${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=sha,prefix={{branch}}-
          type=semver,pattern={{version}}
    
    - name: Build and push Docker image
      uses: docker/build-push-action@v4
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    - name: Scan Docker image for vulnerabilities
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: ${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Upload Trivy results to GitHub Security
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

  # Job 4: Deploy to Staging
  deploy-staging:
    runs-on: ubuntu-latest
    needs: build-docker
    if: github.ref == 'refs/heads/develop'
    environment:
      name: staging
      url: https://staging.example.com
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Setup kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'latest'
    
    - name: Configure kubectl
      run: |
        mkdir -p $HOME/.kube
        echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > $HOME/.kube/config
    
    - name: Deploy to staging
      run: |
        kubectl set image deployment/myapp \
          myapp=${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}:develop-${{ github.sha }} \
          --namespace=staging
        
        kubectl rollout status deployment/myapp --namespace=staging
    
    - name: Run smoke tests
      run: |
        curl -f https://staging.example.com/health || exit 1
    
    - name: Notify Slack
      uses: slackapi/slack-github-action@v1
      with:
        payload: |
          {
            "text": "âœ… Deployed to Staging: ${{ github.sha }}",
            "blocks": [
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "Deployment to *Staging* completed\nCommit: `${{ github.sha }}`\nAuthor: ${{ github.actor }}"
                }
              }
            ]
          }
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}

  # Job 5: Deploy to Production
  deploy-production:
    runs-on: ubuntu-latest
    needs: build-docker
    if: github.ref == 'refs/heads/main'
    environment:
      name: production
      url: https://example.com
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Setup kubectl
      uses: azure/setup-kubectl@v3
    
    - name: Configure kubectl
      run: |
        mkdir -p $HOME/.kube
        echo "${{ secrets.KUBE_CONFIG_PROD }}" | base64 -d > $HOME/.kube/config
    
    - name: Deploy to production (Blue-Green)
      run: |
        # Deploy to green environment
        kubectl set image deployment/myapp-green \
          myapp=${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}:main-${{ github.sha }} \
          --namespace=production
        
        # Wait for rollout
        kubectl rollout status deployment/myapp-green --namespace=production
        
        # Run health checks
        sleep 30
        kubectl exec -n production deployment/myapp-green -- curl -f http://localhost:8080/health
    
    - name: Switch traffic to green
      run: |
        # Update service to point to green deployment
        kubectl patch service myapp-service -n production \
          -p '{"spec":{"selector":{"version":"green"}}}'
    
    - name: Monitor for 5 minutes
      run: |
        sleep 300
        ERROR_RATE=$(kubectl logs -n production deployment/myapp-green --tail=1000 | grep ERROR | wc -l)
        if [ $ERROR_RATE -gt 10 ]; then
          echo "High error rate detected, rolling back"
          kubectl patch service myapp-service -n production \
            -p '{"spec":{"selector":{"version":"blue"}}}'
          exit 1
        fi
    
    - name: Create GitHub Release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: v${{ github.run_number }}
        release_name: Release v${{ github.run_number }}
        body: |
          Deployed to production
          Commit: ${{ github.sha }}
          Author: ${{ github.actor }}
        draft: false
        prerelease: false
    
    - name: Notify team
      uses: slackapi/slack-github-action@v1
      with:
        payload: |
          {
            "text": "ğŸš€ Production Deployment Successful!",
            "blocks": [
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "*Production Deployment*\nVersion: v${{ github.run_number }}\nCommit: `${{ github.sha }}`\nAuthor: ${{ github.actor }}\nURL: https://example.com"
                }
              }
            ]
          }
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}
```

**Project Structure:**
```
.
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci-cd.yml
â”‚       â””â”€â”€ pr-check.yml
â”œâ”€â”€ src/
â”œâ”€â”€ tests/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ package.json
â””â”€â”€ k8s/
    â”œâ”€â”€ deployment.yaml
    â””â”€â”€ service.yaml
```

**Dockerfile (optimized):**
```dockerfile
# Multi-stage build
FROM node:18-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
RUN npm run build

FROM node:18-alpine
RUN addgroup -g 1000 appuser && \
    adduser -D -u 1000 -G appuser appuser
WORKDIR /app
COPY --from=builder --chown=appuser:appuser /app/dist ./dist
COPY --from=builder --chown=appuser:appuser /app/node_modules ./node_modules
COPY --chown=appuser:appuser package*.json ./
USER appuser
EXPOSE 8080
HEALTHCHECK --interval=30s --timeout=3s \
  CMD node -e "require('http').get('http://localhost:8080/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"
CMD ["node", "dist/server.js"]
```

**Setup GitHub Secrets:**
```bash
# Required secrets in GitHub repository settings:
KUBE_CONFIG_STAGING   # Base64 encoded kubeconfig
KUBE_CONFIG_PROD      # Base64 encoded kubeconfig
SLACK_WEBHOOK         # Slack webhook URL
SNYK_TOKEN           # Snyk API token

# Generate kubeconfig secret:
cat ~/.kube/config | base64 | pbcopy
# Paste in GitHub repo â†’ Settings â†’ Secrets
```

**Kubernetes manifests:**
```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: blue
  template:
    metadata:
      labels:
        app: myapp
        version: blue
    spec:
      containers:
      - name: myapp
        image: ghcr.io/company/myapp:main-abc123
        ports:
        - containerPort: 8080
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
```

**Key Features:**

1. **Multi-job workflow**: Build â†’ Test â†’ Security â†’ Docker â†’ Deploy
2. **Parallel execution**: Security scan runs parallel to build
3. **Artifact caching**: NPM cache, Docker layer cache
4. **Security scanning**: Snyk, Trivy, npm audit
5. **Environment-specific deploys**: Staging (develop), Production (main)
6. **Manual approvals**: GitHub Environments with protection rules
7. **Blue-green deployment**: Zero downtime
8. **Automatic rollback**: On high error rate
9. **Notifications**: Slack integration
10. **Release management**: Auto-create GitHub releases

This is a production-grade CI/CD pipeline used in real-world scenarios!"

---

# SECTION 3: HARDCORE LEVEL QUESTIONS

## 3.1 Production Architecture

**Q17: Design a multi-region, highly available Kubernetes architecture for a global e-commerce platform. Explain your disaster recovery strategy.**

**Answer:**
"This requires careful planning for availability, latency, and data consistency.

**Architecture Overview:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Global Load Balancer (CloudFlare/AWS R53)   â”‚
â”‚                    Health-based routing                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                        â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   US-EAST-1      â”‚    â”‚   EU-WEST-1      â”‚
    â”‚   Region         â”‚    â”‚   Region         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                        â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   APAC Region    â”‚    â”‚  Backup Region   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Each Region:
â”œâ”€â”€ Multi-AZ Kubernetes Cluster (EKS/GKE/AKS)
â”œâ”€â”€ Multi-AZ Database (Aurora Global/CockroachDB)
â”œâ”€â”€ Distributed Cache (Redis Cluster)
â”œâ”€â”€ CDN (CloudFront/Fastly)
â””â”€â”€ Backup Storage (S3 cross-region replication)
```

**Regional Kubernetes Setup:**

```yaml
# Each region has:

1. Kubernetes Cluster (Multi-AZ):
   - 3 Master nodes (across 3 AZs)
   - Worker nodes auto-scaled (min 6, across 3 AZs)
   - Pod Anti-Affinity for critical services

2. Application Tier:
   apiVersion: apps/v1
   kind: Deployment
   metadata:
     name: frontend
   spec:
     replicas: 6  # 2 per AZ
     template:
       spec:
         affinity:
           podAntiAffinity:
             requiredDuringSchedulingIgnoredDuringExecution:
             - labelSelector:
                 matchExpressions:
                 - key: app
                   operator: In
                   values:
                   - frontend
               topologyKey: topology.kubernetes.io/zone
         containers:
         - name: frontend
           image: frontend:v1.0
           resources:
             requests:
               memory: "512Mi"
               cpu: "500m"
             limits:
               memory: "1Gi"
               cpu: "1000m"

3. Database Layer:
   - Primary: Aurora Global (US-EAST-1)
   - Read Replicas: In each region
   - Replication lag: <1 second
   - Automatic failover: <30 seconds

4. Cache Layer:
   - Redis Cluster (3 masters, 3 replicas per region)
   - Cross-region cache invalidation via Pub/Sub

5. Storage:
   - S3 with Cross-Region Replication
   - RTO: < 1 hour
   - RPO: < 5 minutes (continuous replication)
```

**Traffic Routing Strategy:**

```yaml
# CloudFlare Load Balancer Configuration

Pools:
  - name: US-Primary
    origins:
      - us-east-1.example.com
      - us-west-2.example.com
    health_check:
      path: /health
      interval: 60s
      retries: 2
      timeout: 5s
    
  - name: EU-Primary
    origins:
      - eu-west-1.example.com
      - eu-central-1.example.com
    
  - name: APAC-Primary
    origins:
      - ap-southeast-1.example.com
      - ap-northeast-1.example.com

Routing:
  - Geo-routing (primary):
      US traffic â†’ US-Primary pool
      EU traffic â†’ EU-Primary pool
      APAC traffic â†’ APAC-Primary pool
  
  - Failover (secondary):
      If US-Primary unhealthy â†’ EU-Primary
      If EU-Primary unhealthy â†’ US-Primary
  
  - Latency-based (tertiary):
      Route to lowest latency healthy region
```

**Disaster Recovery Strategy:**

**RTO (Recovery Time Objective): 15 minutes**
**RPO (Recovery Point Objective): 5 minutes**

**Scenario 1: Complete Regional Failure**

```bash
# Detection (30 seconds):
- Health checks fail across all AZs in region
- CloudFlare automatically routes traffic away
- PagerDuty alerts on-call team

# Automatic Actions (5 minutes):
# 1. Traffic rerouted to healthy regions
# 2. Database fails over to next region
# 3. Cache warming in backup region
# 4. Monitoring confirms services healthy

# Manual Actions (10 minutes):
# 1. Verify all systems functional
# 2. Check data consistency
# 3. Scale up backup region if needed
# 4. Communicate with stakeholders

# Example: US-EAST-1 goes down
Before:
  US traffic â†’ US-EAST-1 (100%)

After (automatic):
  US traffic â†’ US-WEST-2 (50%) + EU-WEST-1 (50%)
  
Result:
  - Users experience slight latency increase
  - No data loss (RPO met)
  - Service restored in <15 minutes (RTO met)
```

**Scenario 2: Database Corruption**

```bash
# Detection:
- Application errors increase
- Database queries failing
- Automated alerts trigger

# Recovery Steps:
# 1. Stop writes to corrupted database (2 minutes)
kubectl scale deployment backend --replicas=0 -n us-east-1

# 2. Promote read replica to primary (3 minutes)
aws rds promote-read-replica \
  --db-instance-identifier replica-eu-west-1

# 3. Point applications to new primary (2 minutes)
kubectl set env deployment/backend \
  DB_HOST=new-primary.eu-west-1.rds.amazonaws.com

# 4. Restore from last good backup if needed (8 minutes)
aws rds restore-db-instance-to-point-in-time \
  --source-db-instance original \
  --target-db-instance restored \
  --restore-time 2024-02-15T10:00:00Z

Total time: 15 minutes (within RTO)
Data loss: <5 minutes (within RPO)
```

**Scenario 3: Kubernetes Control Plane Failure**

```bash
# Self-healing:
- Managed Kubernetes (EKS/GKE) automatically recovers control plane
- Worker nodes continue running existing pods
- New deployments queued until control plane restored

# If managed service fails:
# 1. Promote standby cluster (pre-configured)
# 2. DNS cutover to standby cluster
# 3. Restore from GitOps (ArgoCD/Flux)

Recovery time: 10 minutes
```

**Data Consistency Strategy:**

```yaml
Write Strategy:
  - Synchronous writes to primary DB
  - Asynchronous replication to other regions
  - Conflict resolution: Last-write-wins with timestamp

Read Strategy:
  - Read from local region (low latency)
  - Critical reads from primary (consistency)
  - Stale reads acceptable for non-critical data

Example - Order Processing:
  1. User places order (writes to US-EAST-1 primary)
  2. Order replicated to EU/APAC within 1 second
  3. EU user sees order after 1-2 second delay (acceptable)
  4. Critical operations (payment) always from primary
```

**Backup Strategy:**

```yaml
Automated Backups:
  Database:
    - Continuous backup to S3
    - Point-in-time recovery (5-minute granularity)
    - Cross-region backup replication
    - Retention: 30 days
  
  Kubernetes State:
    - Velero backups every 6 hours
    - Backup includes: PVCs, ConfigMaps, Secrets
    - Stored in S3 with versioning
    - Tested restore monthly
  
  Application Code:
    - Git repository (source of truth)
    - GitOps ensures cluster state matches Git
    - Can rebuild entire cluster from Git

Restore Testing:
  - Quarterly disaster recovery drill
  - Restore in isolated environment
  - Verify RTO/RPO met
  - Document lessons learned
```

**Monitoring & Alerting:**

```yaml
Metrics Collected:
  - Application: Response time, error rate, throughput
  - Infrastructure: CPU, memory, disk, network
  - Database: Replication lag, query performance
  - Business: Orders/minute, revenue, conversion rate

Alert Levels:
  P1 (Page immediately):
    - Service down >2 minutes
    - Error rate >5%
    - Database replication lag >60 seconds
  
  P2 (Page during business hours):
    - Response time >2 seconds
    - Disk usage >80%
    - Certificate expiring <7 days
  
  P3 (Create ticket):
    - Minor performance degradation
    - Non-critical service issues

Runbook for each alert:
  - Symptoms
  - Investigation steps
  - Resolution steps
  - Escalation path
```

**Cost Optimization:**

```yaml
Multi-region is expensive, so optimize:

1. Regional distribution:
   - US (primary): 40% of infrastructure
   - EU: 30%
   - APAC: 20%
   - DR region: 10% (scaled up on demand)

2. Resource optimization:
   - Spot instances for non-critical workloads (60% cost savings)
   - Reserved instances for baseline (40% savings)
   - Auto-scaling (save on off-peak)

3. Data transfer:
   - CloudFront CDN (reduce origin bandwidth)
   - Cross-region replication only for critical data
   - Compress data in transit

4. Database:
   - Aurora Serverless v2 (pay per use)
   - Delete old backups (keep 30 days only)
   - Optimize queries (reduce IOPS)

Estimated costs:
  - Multi-region active-active: $50K/month
  - Single region: $15K/month
  - Cost of downtime: $100K/hour
  ROI: 2-hour outage prevented = investment justified
```

**Real-world Numbers (from experience):**

```yaml
E-commerce platform handling:
  - 10,000 requests/second peak
  - 100TB data
  - 50 microservices
  - 99.99% uptime SLA

Architecture:
  - 3 active regions (US, EU, APAC)
  - 1 backup region (triggered on demand)
  - 120 Kubernetes nodes total
  - 500 pods running

Incident Response Times:
  - Region failure detection: <1 minute
  - Automatic failover: 5 minutes
  - Manual intervention (if needed): +10 minutes
  - Total recovery: <15 minutes

Achieved:
  - 99.995% actual uptime
  - Zero data loss in 2 years
  - 3 major incidents successfully handled
  - Average incident duration: 12 minutes
```

**Key Principles:**

1. **Redundancy at every layer** (compute, storage, network, power)
2. **Automated recovery** (no human in critical path)
3. **Regular testing** (quarterly DR drills)
4. **Clear runbooks** (documented procedures)
5. **Cost-aware** (balance availability vs. cost)
6. **Monitor everything** (know before customers do)
7. **Iterate and improve** (learn from each incident)

This architecture provides enterprise-grade reliability for critical applications."

---

## 3.2 Complex Troubleshooting

**Q18: Production Kubernetes cluster is experiencing intermittent pod crashes with OOMKilled errors, but memory metrics show pods using only 60% of their limit. How do you troubleshoot this?**

**Answer:**
"This is a challenging scenario - apparent memory available but OOMKilled events. Systematic investigation required.

**Initial Assessment:**

```bash
# 1. Verify the symptom
kubectl get pods -A | grep OOMKilled

# 2. Check recent events
kubectl get events --sort-by='.lastTimestamp' | grep OOM

# 3. Check specific pod that crashed
kubectl describe pod <pod-name> -n <namespace>

# Look for:
State:          Terminated
  Reason:       OOMKilled
  Exit Code:    137
```

**Hypothesis 1: Memory Spike Not Captured by Metrics**

**Problem:** Metrics show average/current usage, might miss sudden spikes.

**Investigation:**
```bash
# Check detailed memory metrics
kubectl top pod <pod-name> -n <namespace> --containers

# Better: Check Prometheus for detailed history
# PromQL query
container_memory_working_set_bytes{pod="<pod-name>"}

# Look for spikes that exceed limits
max_over_time(container_memory_working_set_bytes{pod="<pod-name>"}[5m])
```

**Solution:**
```yaml
# If spikes are real, increase memory limits
resources:
  requests:
    memory: "512Mi"
  limits:
    memory: "1Gi"  # Increased from 800Mi

# Add buffer for spikes (20-30% headroom)
```

---

**Hypothesis 2: Memory Requests vs Limits Mismatch**

**Problem:** Node has insufficient memory, even though pod hasn't hit its limit.

**Investigation:**
```bash
# Check node memory pressure
kubectl describe node <node-name> | grep -A 5 "Allocated resources"

# Output might show:
# Memory Requests: 28Gi (90% of node capacity)
# Memory Limits: 48Gi (150% of node capacity)
# Available: 32Gi

# This means node is overcommitted!
```

**What's happening:**
```
Node has 32Gi total memory
Requests: 28Gi (scheduled based on requests)
Limits: 48Gi (if all pods hit limits = trouble)

When pods try to use more than requests:
- Node runs out of actual memory
- Kernel OOM killer activates
- Kills pods even if under their limits
```

**Solution:**
```yaml
# Option 1: Reduce overcommitment
# Set requests closer to limits
resources:
  requests:
    memory: "800Mi"  # Was 512Mi
  limits:
    memory: "1Gi"

# Option 2: Add QoS class
# Guaranteed QoS (requests = limits)
resources:
  requests:
    memory: "1Gi"
  limits:
    memory: "1Gi"  # Same as requests

# Option 3: Add more nodes
kubectl scale nodepool default-pool --node-count=10
```

---

**Hypothesis 3: Memory Leak in Application**

**Problem:** Application gradually leaks memory until OOM.

**Investigation:**
```bash
# Check memory growth over time
kubectl logs <pod-name> -n <namespace> --previous | grep -i memory

# Better: Prometheus query for trend
increase(container_memory_working_set_bytes{pod="<pod-name>"}[1h])

# Take heap dump (for Java apps)
kubectl exec <pod-name> -n <namespace> -- \
  jmap -dump:format=b,file=/tmp/heap.bin <PID>

# Copy heap dump for analysis
kubectl cp <pod-name>:/tmp/heap.bin ./heap.bin -n <namespace>

# Analyze with MAT (Memory Analyzer Tool)
```

**Solution:**
```yaml
# Short-term: Restart pods periodically
apiVersion: batch/v1
kind: CronJob
metadata:
  name: restart-leaky-pods
spec:
  schedule: "0 2 * * *"  # 2 AM daily
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: kubectl
            image: bitnami/kubectl
            command:
            - kubectl
            - rollout
            - restart
            - deployment/leaky-app
            - -n
            - production

# Long-term: Fix the memory leak in code
# - Profile application
# - Fix resource cleanup
# - Add proper garbage collection
```

---

**Hypothesis 4: Container vs. Pod Memory**

**Problem:** Kubernetes tracks memory at container level, not pod level.

**Investigation:**
```bash
# Check all containers in pod
kubectl top pod <pod-name> -n <namespace> --containers

# Output:
POD          CONTAINER    CPU    MEMORY
myapp-pod    main-app     100m   400Mi
myapp-pod    sidecar      50m    300Mi
myapp-pod    init-proxy   20m    200Mi
# Total: 900Mi

# But limits might be:
main-app: 500Mi
sidecar: 400Mi
init-proxy: 200Mi
# Total: 1100Mi

# If node has limited memory, sum matters!
```

**Solution:**
```yaml
# Adjust limits for all containers
spec:
  containers:
  - name: main-app
    resources:
      limits:
        memory: "600Mi"  # Increased
  - name: sidecar
    resources:
      limits:
        memory: "300Mi"  # Reduced (if possible)
```

---

**Hypothesis 5: System Overhead Not Accounted**

**Problem:** Node reserves memory for system processes (kubelet, kernel).

**Investigation:**
```bash
# Check node allocatable memory
kubectl describe node <node-name> | grep -A 10 "Allocatable:"

# Example:
Capacity:
  memory: 32Gi
Allocatable:
  memory: 29Gi  # 3Gi reserved for system

# If pods request 29Gi but node has overhead:
# - Kernel buffers: 1Gi
# - Kubelet overhead: 500Mi
# - Node-level daemons: 1Gi
# Actual available for pods: ~26Gi
```

**Solution:**
```yaml
# Configure node to reserve more memory
# (on node or cluster level)
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
systemReserved:
  memory: "2Gi"
kubeReserved:
  memory: "1Gi"
evictionHard:
  memory.available: "500Mi"

# This leaves less for pods but prevents OOM
```

---

**Hypothesis 6: Swap Disabled (Kubernetes Requirement)**

**Problem:** Kubernetes requires swap disabled, so no memory overflow protection.

**Investigation:**
```bash
# Check if swap is enabled on nodes
kubectl debug node/<node-name> -it --image=ubuntu

# In debug pod:
swapon --show
# If empty: swap is disabled (expected)

# Check kernel OOM kills
dmesg | grep -i "out of memory"
```

**Finding:** This is expected behavior. Without swap, OOM killer is aggressive.

**Solution:**
```yaml
# Can't enable swap (Kubernetes limitation)
# Must properly size resources

# Option: Use memory.high cgroup limit
# (Available in newer kernels)
# Throttles before OOM instead of killing
```

---

**Hypothesis 7: Burstable QoS and Node Pressure**

**Problem:** Pod has Burstable QoS, gets killed first under node pressure.

**Investigation:**
```bash
# Check pod QoS class
kubectl get pod <pod-name> -n <namespace> -o jsonpath='{.status.qosClass}'

# QoS Classes:
# - Guaranteed: requests = limits (last to be killed)
# - Burstable: requests < limits (killed second)
# - BestEffort: no requests/limits (killed first)

# Check node memory pressure
kubectl describe node <node-name> | grep MemoryPressure
```

**Solution:**
```yaml
# Upgrade to Guaranteed QoS
# Set requests = limits
resources:
  requests:
    memory: "1Gi"
    cpu: "500m"
  limits:
    memory: "1Gi"  # Same as request
    cpu: "500m"    # Same as request

# Guaranteed pods are last to be evicted
```

---

**Hypothesis 8: Shared Memory (/dev/shm)**

**Problem:** Application using shared memory (tmpfs) counts against memory limit.

**Investigation:**
```bash
# Check shared memory usage
kubectl exec <pod-name> -n <namespace> -- df -h /dev/shm

# Default /dev/shm size is 64Mi
# If app uses more, counts against container memory

# Check if app is using shm
kubectl exec <pod-name> -n <namespace> -- \
  lsof | grep /dev/shm
```

**Solution:**
```yaml
# Increase shm size
spec:
  containers:
  - name: app
    volumeMounts:
    - name: dshm
      mountPath: /dev/shm
  volumes:
  - name: dshm
    emptyDir:
      medium: Memory
      sizeLimit: "256Mi"  # Explicit limit

# Account for this in memory limits
resources:
  limits:
    memory: "1.2Gi"  # 1Gi app + 256Mi shm
```

---

**Complete Diagnostic Script:**

```bash
#!/bin/bash
# oom-diagnose.sh

POD=$1
NAMESPACE=${2:-default}

echo "=== OOM Diagnostic for $POD ==="

echo "
1. Current State:"
kubectl get pod $POD -n $NAMESPACE

echo "
2. Recent Events:"
kubectl get events -n $NAMESPACE --field-selector involvedObject.name=$POD

echo "
3. Resource Configuration:"
kubectl get pod $POD -n $NAMESPACE -o json | \
  jq '.spec.containers[] | {name: .name, resources: .resources}'

echo "
4. QoS Class:"
kubectl get pod $POD -n $NAMESPACE -o jsonpath='{.status.qosClass}'

echo "
5. Node Capacity:"
NODE=$(kubectl get pod $POD -n $NAMESPACE -o jsonpath='{.spec.nodeName}')
kubectl describe node $NODE | grep -A 10 "Allocated resources"

echo "
6. Memory Usage History (if Prometheus available):"
# This requires prometheus installed
# kubectl port-forward -n monitoring svc/prometheus 9090:9090 &
# curl -s 'http://localhost:9090/api/v1/query?query=container_memory_working_set_bytes{pod="'$POD'"}' | jq .

echo "
7. Previous Logs (if available):"
kubectl logs $POD -n $NAMESPACE --previous | tail -50

echo "
8. Check for memory leaks:"
kubectl top pod $POD -n $NAMESPACE --containers
```

**Run diagnostic:**
```bash
chmod +x oom-diagnose.sh
./oom-diagnose.sh myapp-pod production
```

---

**Resolution Checklist:**

```
âœ“ Check actual memory usage patterns (not just averages)
âœ“ Verify requests vs limits (avoid overcommitment)
âœ“ Check for memory leaks (profile application)
âœ“ Account for all containers in pod
âœ“ Consider node system overhead
âœ“ Verify QoS class (upgrade to Guaranteed if critical)
âœ“ Check shared memory usage (/dev/shm)
âœ“ Review node allocatable memory
âœ“ Monitor memory pressure events
âœ“ Test with increased limits

Prevention:
âœ“ Set appropriate memory requests and limits
âœ“ Use Guaranteed QoS for critical services
âœ“ Monitor memory trends
âœ“ Load test before production
âœ“ Add memory headroom (20-30%)
âœ“ Configure alerts for memory pressure
âœ“ Regular application profiling
âœ“ Periodic pod restarts (if necessary)
```

**Real Example Resolution:**

```yaml
# Original configuration (problematic)
resources:
  requests:
    memory: "512Mi"
  limits:
    memory: "800Mi"

# Problem: Spikes to 900Mi â†’ OOMKilled
# Node overcommitted (requests vs actual usage)

# Solution applied:
resources:
  requests:
    memory: "1Gi"     # Increased to reflect actual usage
  limits:
    memory: "1.2Gi"   # Added 20% headroom for spikes

# Result:
# - No more OOMKilled events
# - Stable memory usage
# - Slightly higher cost (acceptable for stability)
```

**Key Takeaway:** OOMKilled with apparent memory headroom usually indicates:
1. Unaccounted memory usage (spikes, shared memory)
2. Node-level resource contention
3. QoS-based eviction under pressure

Proper diagnosis requires looking beyond pod-level metrics to node-level resource availability and kernel behavior."

---

## 3.3 Security Hardening

**Q19: Your Kubernetes cluster was compromised through a container escape vulnerability. Walk me through your incident response process and how you'd harden the cluster post-incident.**

**Answer:**

"Container escape is a severe incident. Here's the complete response:

**PHASE 1: DETECTION & CONTAINMENT (First 30 Minutes)**

**Step 1: Confirm Breach (Minutes 0-5)**
```bash
# Indicators of compromise
- Unusual process in container (e.g., /bin/bash spawned)
- Unexpected network connections
- File modifications in /var, /etc
- Privilege escalation attempts

# Check audit logs
kubectl logs -n kube-system kube-apiserver-* | grep -i "privilege"

# Check for suspicious pods
kubectl get pods -A -o json | \
  jq '.items[] | select(.spec.containers[].securityContext.privileged == true)'

# Check runtime security alerts (if Falco installed)
kubectl logs -n falco -l app=falco | grep -i "Terminal shell"
```

**Step 2: Isolate Affected Resources (Minutes 5-10)**
```bash
# Immediately isolate compromised pod
# Option 1: Network Policy (deny all)
kubectl apply -f - <<EOF
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all-compromised
  namespace: affected-namespace
spec:
  podSelector:
    matchLabels:
      app: compromised-app
  policyTypes:
  - Ingress
  - Egress
EOF

# Option 2: Drain node if node compromised
kubectl cordon <node-name>
kubectl drain <node-name> --ignore-daemonsets --delete-emptydir-data

# Take snapshot for forensics
kubectl debug <compromised-pod> --image=busybox --copy-to=forensic-pod
kubectl cp forensic-pod:/var/log /local/forensics/

# Preserve evidence
kubectl logs <compromised-pod> > incident-logs.txt
kubectl describe pod <compromised-pod> > incident-describe.txt
```

**Step 3: Kill Compromised Workloads (Minutes 10-15)**
```bash
# Delete compromised pods
kubectl delete pod <compromised-pod> -n <namespace>

# Scale down deployment
kubectl scale deployment <compromised-deployment> --replicas=0

# If entire namespace compromised
kubectl delete namespace <compromised-namespace> --grace-period=0
```

**Step 4: Revoke Access (Minutes 15-20)**
```bash
# Rotate service account tokens
kubectl delete secret -n <namespace> $(kubectl get secrets -n <namespace> | grep default-token | awk '{print $1}')

# Revoke compromised credentials
kubectl delete serviceaccount <compromised-sa> -n <namespace>

# Rotate kubeconfig secrets if exposed
kubectl delete secret kubeconfig-secret -n <namespace>

# Revoke cloud IAM roles if compromised
aws iam detach-role-policy --role-name PodRole --policy-arn arn:aws:iam::policy/S3Access
```

**Step 5: Notify & Communicate (Minutes 20-30)**
```bash
# Incident response team
- Security team
- On-call engineers  
- Management
- Legal (if data breach)
- Customers (if customer data exposed)

# Create incident channel
# Slack: #incident-2024-02-15-container-escape

# Initial communication:
"SECURITY INCIDENT: Container escape detected in production cluster.
Status: CONTAINED
Impact: <namespace> isolated, no customer data accessed
Actions: Forensic analysis in progress
ETA: Full report in 4 hours"
```

---

**PHASE 2: INVESTIGATION (Hours 1-4)**

**Forensic Analysis:**
```bash
# Analyze container image
docker save compromised-image:tag > compromised-image.tar
trivy image compromised-image:tag --severity CRITICAL,HIGH

# Check for malicious code
docker run --rm -it compromised-image:tag /bin/sh
find / -name "*.sh" -type f -mtime -1  # Recently modified scripts
ps aux  # Check running processes

# Analyze Kubernetes audit logs
kubectl logs -n kube-system kube-apiserver-* > audit.log
grep "ResponseComplete" audit.log | jq .

# Look for:
# - Privilege escalation attempts
# - Secret access
# - ConfigMap modifications
# - Exec into pods

# Check node logs
kubectl debug node/<node-name> -it --image=ubuntu
journalctl -u kubelet | grep -i error
dmesg | grep -i "segfault\|error"

# Network traffic analysis (if captured)
kubectl logs -n kube-system kube-proxy-* 
# Look for unusual destinations
```

**Root Cause Identification:**

Common container escape vectors:
```yaml
1. Privileged containers:
   spec:
     containers:
     - securityContext:
         privileged: true  # â† VULNERABILITY

2. Host path mounts:
   volumeMounts:
   - name: host
     mountPath: /host  # Mounts host filesystem

3. Host network/PID namespace:
   spec:
     hostNetwork: true  # â† Can access host network
     hostPID: true      # â† Can see host processes

4. Excessive capabilities:
   securityContext:
     capabilities:
       add: ["SYS_ADMIN"]  # â† Allows many exploits

5. Vulnerable container runtime:
   - Outdated Docker/containerd
   - Known CVEs (e.g., runc CVE-2019-5736)
```

---

**PHASE 3: HARDENING (Days 1-7)**

**1. Pod Security Standards:**
```yaml
# Enforce restricted Pod Security Standard
apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted
```

**2. Security Context (enforce non-root):**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-app
spec:
  template:
    spec:
      # Pod-level security context
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 2000
        seccompProfile:
          type: RuntimeDefault
      
      containers:
      - name: app
        image: app:secure
        # Container-level security context
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
          capabilities:
            drop:
              - ALL
            add:
              - NET_BIND_SERVICE  # Only if needed
        
        # Use emptyDir for writable directories
        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: cache
          mountPath: /var/cache
      
      volumes:
      - name: tmp
        emptyDir: {}
      - name: cache
        emptyDir: {}
```

**3. Network Policies (Zero Trust):**
```yaml
# Default deny all
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress

---
# Allow specific traffic only
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-frontend-to-backend
  namespace: production
spec:
  podSelector:
    matchLabels:
      app: backend
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend
    ports:
    - protocol: TCP
      port: 8080

---
# Egress: Allow only DNS and specific services
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: backend-egress
  namespace: production
spec:
  podSelector:
    matchLabels:
      app: backend
  policyTypes:
  - Egress
  egress:
  # Allow DNS
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: UDP
      port: 53
  # Allow database
  - to:
    - podSelector:
        matchLabels:
          app: postgres
    ports:
    - protocol: TCP
      port: 5432
```

**4. RBAC Hardening:**
```yaml
# Principle of least privilege
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: app-role
  namespace: production
rules:
# Only what's needed
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["secrets"]
  resourceNames: ["app-secret"]  # Specific secret only
  verbs: ["get"]

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: app-sa
  namespace: production
automountServiceAccountToken: false  # Don't auto-mount token

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: app-rolebinding
  namespace: production
subjects:
- kind: ServiceAccount
  name: app-sa
  namespace: production
roleRef:
  kind: Role
  name: app-role
  apiGroup: rbac.authorization.k8s.io
```

**5. Admission Controllers:**
```yaml
# Enable Pod Security Admission
# In kube-apiserver config:
--enable-admission-plugins=NodeRestriction,PodSecurity

# OPA Gatekeeper policies
apiVersion: templates.gatekeeper.sh/v1beta1
kind: ConstraintTemplate
metadata:
  name: k8spspprivilegedcontainer
spec:
  crd:
    spec:
      names:
        kind: K8sPSPPrivilegedContainer
  targets:
    - target: admission.k8s.gatekeeper.sh
      rego: |
        package k8spspprivileged
        
        violation[{"msg": msg}] {
          c := input_containers[_]
          c.securityContext.privileged
          msg := sprintf("Privileged container not allowed: %v", [c.name])
        }
        
        input_containers[c] {
          c := input.review.object.spec.containers[_]
        }

---
# Apply constraint
apiVersion: constraints.gatekeeper.sh/v1beta1
kind: K8sPSPPrivilegedContainer
metadata:
  name: deny-privileged-containers
spec:
  match:
    kinds:
      - apiGroups: [""]
        kinds: ["Pod"]
```

**6. Runtime Security (Falco):**
```yaml
# Install Falco
helm repo add falcosecurity https://falcosecurity.github.io/charts
helm install falco falcosecurity/falco \
  --namespace falco \
  --set falcosidekick.enabled=true \
  --set falcosidekick.webui.enabled=true

# Custom Falco rules
# /etc/falco/falco_rules.local.yaml
- rule: Terminal shell in container
  desc: A shell was spawned in a container
  condition: >
    spawned_process and container and
    shell_procs and proc.tty != 0
  output: >
    Shell spawned in container
    (user=%user.name container=%container.name 
    shell=%proc.name parent=%proc.pname)
  priority: WARNING

- rule: Sensitive file opened for reading
  desc: Attempt to read sensitive file
  condition: >
    open_read and container and
    (fd.name startswith /etc/shadow or
     fd.name startswith /etc/passwd)
  output: >
    Sensitive file opened
    (user=%user.name file=%fd.name 
    container=%container.name)
  priority: CRITICAL
```

**7. Image Scanning & Signing:**
```yaml
# Scan images in CI/CD
- name: Scan image
  run: |
    trivy image --severity CRITICAL,HIGH \
      --exit-code 1 \
      myimage:latest

# Sign images
- name: Sign image
  run: |
    cosign sign --key cosign.key \
      myimage:latest

# Verify signatures in cluster
apiVersion: v1
kind: Pod
metadata:
  annotations:
    # Require signature
    cosign.sigstore.dev/signature: required
spec:
  containers:
  - name: app
    image: myimage:latest
```

**8. Audit Logging:**
```yaml
# Enable audit logging
# kube-apiserver audit policy
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
# Log everything at RequestResponse level
- level: RequestResponse
  verbs: ["create", "update", "patch", "delete"]
  resources:
  - group: ""
    resources: ["secrets", "configmaps"]
  - group: "rbac.authorization.k8s.io"
    resources: ["roles", "rolebindings"]

# Log metadata for reads
- level: Metadata
  verbs: ["get", "list", "watch"]

# Don't log health checks
- level: None
  users: ["system:kube-proxy"]
  verbs: ["watch"]
  resources:
  - group: ""
    resources: ["endpoints", "services"]
```

**9. Secrets Management:**
```yaml
# External Secrets Operator (sync from Vault)
apiVersion: external-secrets.io/v1beta1
kind: SecretStore
metadata:
  name: vault-backend
  namespace: production
spec:
  provider:
    vault:
      server: "https://vault.company.com"
      path: "secret"
      version: "v2"
      auth:
        kubernetes:
          mountPath: "kubernetes"
          role: "external-secrets"

---
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: app-secret
  namespace: production
spec:
  refreshInterval: 1h
  secretStoreRef:
    name: vault-backend
    kind: SecretStore
  target:
    name: app-secret
    creationPolicy: Owner
  data:
  - secretKey: password
    remoteRef:
      key: app/credentials
      property: password
```

**10. Node Hardening:**
```bash
# On each node:

# 1. Minimal OS (use hardened AMI)
# 2. Disable unnecessary services
systemctl disable bluetooth
systemctl disable cups

# 3. Kernel hardening
sysctl -w kernel.dmesg_restrict=1
sysctl -w kernel.kptr_restrict=2
sysctl -w net.ipv4.conf.all.send_redirects=0

# 4. AppArmor/SELinux
apt-get install apparmor apparmor-utils
aa-enforce /etc/apparmor.d/*

# 5. Regular updates
apt-get update && apt-get upgrade -y

# 6. CIS benchmark
kube-bench run --targets node
```

---

**PHASE 4: VALIDATION (Week 2)**

```bash
# Penetration testing
- Hire external security firm
- Test for same vulnerability
- Verify hardening measures effective

# Compliance audit
- Review against CIS Kubernetes Benchmark
- Document all changes
- Update security policies

# Team training
- Security awareness training
- Incident response drill
- Code review process updates
```

---

**Incident Report Template:**

```markdown
# Security Incident Report: Container Escape

## Executive Summary
- **Date**: 2024-02-15
- **Severity**: P1 - Critical
- **Impact**: Production namespace compromised
- **Data Breach**: No customer data accessed
- **Downtime**: 15 minutes (namespace isolated)

## Timeline
- 10:00 AM: Alert triggered (unusual process in container)
- 10:05 AM: Incident confirmed, team paged
- 10:10 AM: Namespace isolated
- 10:15 AM: Compromised pods terminated
- 10:30 AM: Credentials rotated
- 2:00 PM: Root cause identified
- Week 1: Hardening measures implemented
- Week 2: Validation completed

## Root Cause
- Privileged container allowed in production
- No Pod Security Standards enforced
- Container ran as root
- Vulnerable container runtime (runc CVE-2019-5736)

## Impact
- 1 namespace compromised
- 3 workloads affected
- No data exfiltration detected
- No customer impact (isolated before external access)

## Resolution
- Implemented Pod Security Standards
- Enforced non-root containers
- Added network policies
- Upgraded container runtime
- Enhanced RBAC
- Deployed runtime security (Falco)
- Implemented image scanning

## Lessons Learned
### What Went Well
- Fast detection (<5 minutes)
- Effective isolation
- No data loss
- Good team coordination

### What Didn't Go Well
- Security controls not strict enough
- No runtime security monitoring
- Delayed forensic analysis (lack of tooling)

### Action Items
1. [DONE] Implement Pod Security Standards
2. [DONE] Deploy Falco for runtime security
3. [IN PROGRESS] Quarterly penetration testing
4. [PLANNED] Security training for all engineers
5. [PLANNED] Regular security audits

## Prevention
- Pod Security Standards enforced
- No privileged containers allowed
- All containers run as non-root
- Network policies default-deny
- Image scanning in CI/CD
- Runtime security monitoring
- Regular security audits
- Incident response drills (quarterly)

## Cost
- Engineering time: 160 hours
- Security tooling: $5K/month (Falco, OPA)
- Penetration testing: $15K
- Training: $3K
**Total**: $23K + ongoing $5K/month

## Sign-off
- Security Team: âœ“
- Engineering Manager: âœ“
- CTO: âœ“
```

**Key Takeaways:**
1. **Assume breach** - layer security (defense in depth)
2. **Principle of least privilege** - minimal permissions always
3. **Runtime security** - detection is as important as prevention
4. **Regular audits** - security is continuous, not one-time
5. **Incident drills** - practice makes perfect
6. **Culture** - security is everyone's responsibility

This comprehensive approach ensures the cluster is hardened against future attacks."

---

## 3.4 Performance Optimization

**Q20: Your application response time degraded from 200ms to 2 seconds after migrating to Kubernetes. No code changes. How do you diagnose and fix this?**

**Answer:**
"10x latency increase with no code changes points to infrastructure. Systematic investigation:

**Step 1: Establish Baseline**

```bash
# Compare before and after
Before (VMs): 200ms p95
After (K8s): 2000ms p95

# Initial questions:
- Same load?
- Same number of instances?
- Same resource allocation?
- Network path changed?
```

**Hypothesis 1: DNS Resolution Latency**

**Problem:** Kubernetes DNS lookups can be slow (ndots:5 default).

**Investigation:**
```bash
# Check DNS query time
kubectl run -it --rm debug --image=busybox --restart=Never -- sh
time nslookup google.com
# If >100ms, DNS is problem

# Check CoreDNS logs
kubectl logs -n kube-system -l k8s-app=kube-dns

# Check ndots setting
kubectl exec -it <pod> -- cat /etc/resolv.conf
# Output:
# search default.svc.cluster.local svc.cluster.local cluster.local
# nameserver 10.96.0.10
# options ndots:5  â† Problem!
```

**Why it's slow:**
```
Application calls: api.external.com

With ndots:5, DNS tries (in order):
1. api.external.com.default.svc.cluster.local (fails)
2. api.external.com.svc.cluster.local (fails)
3. api.external.com.cluster.local (fails)
4. api.external.com.example.com (fails)
5. api.external.com (finally succeeds!)

Each query: ~50ms Ã— 5 = 250ms wasted
```

**Solution:**
```yaml
# Option 1: Use FQDN with trailing dot
# In application code
http.get('https://api.external.com.')  # Trailing dot = absolute

# Option 2: Lower ndots
apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  dnsConfig:
    options:
    - name: ndots
      value: "1"  # Only try cluster domain once
    - name: timeout
      value: "2"
    - name: attempts
      value: "2"
  containers:
  - name: app
    image: myapp:latest

# Option 3: Cache DNS in application
# Use connection pooling with DNS cache
```

**Impact:** This alone can reduce latency by 200-500ms.

---

**Hypothesis 2: Service Mesh Overhead**

**Problem:** Istio/Linkerd sidecar adds latency.

**Investigation:**
```bash
# Check if service mesh installed
kubectl get pods -A | grep -E 'istio|linkerd'

# Check pod has sidecar
kubectl get pod <pod-name> -o jsonpath='{.spec.containers[*].name}'
# If you see "istio-proxy" or "linkerd-proxy" â†’ sidecar present

# Measure sidecar overhead
kubectl exec -it <pod> -- curl -w "@curl-format.txt" http://localhost:8080

# curl-format.txt:
# time_namelookup:  %{time_namelookup}\n
# time_connect:  %{time_connect}\n
# time_appconnect:  %{time_appconnect}\n
# time_pretransfer:  %{time_pretransfer}\n
# time_starttransfer:  %{time_starttransfer}\n
# time_total:  %{time_total}\n
```

**Typical overhead:**
```
Without sidecar: 200ms
With sidecar: 200ms (app) + 3ms (sidecar proxy) = 203ms (acceptable)
But if misconfigured: + 500ms (unacceptable)
```

**Solution:**
```yaml
# Option 1: Optimize sidecar config
apiVersion: v1
kind: ConfigMap
metadata:
  name: istio-sidecar-injector
data:
  config: |
    policy: enabled
    template: |-
      containers:
      - name: istio-proxy
        resources:
          requests:
            cpu: 100m  # Was 10m (too low)
            memory: 128Mi
          limits:
            cpu: 2000m
            memory: 1Gi

# Option 2: Disable for specific workload
apiVersion: apps/v1
kind: Deployment
metadata:
  name: latency-sensitive-app
spec:
  template:
    metadata:
      annotations:
        sidecar.istio.io/inject: "false"

# Option 3: Use host network (bypasses service mesh)
spec:
  hostNetwork: true  # Not recommended, but removes sidecar latency
```

---

**Hypothesis 3: Inefficient Load Balancing**

**Problem:** iptables mode slower than IPVS.

**Investigation:**
```bash
# Check kube-proxy mode
kubectl logs -n kube-system kube-proxy-xxx | grep "Using"
# Output: "Using iptables Proxier"

# Check number of services
kubectl get svc -A | wc -l
# If >1000 services, iptables is very slow

# Measure service access latency
time kubectl exec -it <pod> -- curl http://my-service
```

**Why iptables is slow:**
```
1000 services = 1000s of iptables rules
Each packet traverses ALL rules sequentially
Latency: O(n) where n = number of services
```

**Solution:**
```yaml
# Switch to IPVS mode
# Edit kube-proxy configmap
kubectl edit cm kube-proxy -n kube-system

# Change:
mode: ""  # or "iptables"
# To:
mode: "ipvs"

# Restart kube-proxy
kubectl rollout restart daemonset kube-proxy -n kube-system

# IPVS uses hash table (O(1) lookup)
# Massive improvement for >100 services
```

**Results:**
```
Before (iptables, 1000 services): 500ms overhead
After (IPVS): 5ms overhead
Latency reduced: 495ms
```

---

**Hypothesis 4: Resource Constraints**

**Problem:** CPU throttling due to limits.

**Investigation:**
```bash
# Check CPU throttling
kubectl top pod <pod-name>
CPU: 950m / 1000m (95% of limit)  # Throttled!

# Check throttling metrics (if Prometheus available)
rate(container_cpu_cfs_throttled_seconds_total[5m])

# Check container cgroup stats
kubectl exec <pod> -- cat /sys/fs/cgroup/cpu/cpu.stat
# Look for: nr_throttled, throttled_time
```

**Solution:**
```yaml
# Increase CPU limits
resources:
  requests:
    cpu: "500m"
    memory: "512Mi"
  limits:
    cpu: "2000m"  # Increased from 1000m
    memory: "1Gi"

# Or remove CPU limits (controversial)
resources:
  requests:
    cpu: "500m"
    memory: "512Mi"
  limits:
    # cpu: removed
    memory: "1Gi"  # Keep memory limit for safety
```

---

**Hypothesis 5: Network Policy Overhead**

**Problem:** Too many/complex network policies slow packet processing.

**Investigation:**
```bash
# Check network policies
kubectl get networkpolicies -A

# Check if many policies targeting same pods
kubectl get netpol -n production -o yaml | grep -c "podSelector"

# Test without network policy
kubectl delete netpol <policy-name> -n <namespace>
# Measure latency
# Recreate policy
```

**Solution:**
```yaml
# Simplify network policies

# Bad: Very specific rules (many policies)
# Policy 1: allow frontend â†’ backend
# Policy 2: allow frontend â†’ cache
# Policy 3: allow frontend â†’ database
# Result: Each packet evaluated against all policies

# Good: Consolidated policy
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: frontend-access
spec:
  podSelector:
    matchLabels:
      tier: backend
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tier: frontend
    ports:
    - protocol: TCP
      port: 8080
    - protocol: TCP
      port: 6379  # cache
    - protocol: TCP
      port: 5432  # database
```

---

**Hypothesis 6: Readiness Probe Delays**

**Problem:** Readiness probe too slow, delays pod availability.

**Investigation:**
```bash
# Check readiness probe config
kubectl get pod <pod> -o jsonpath='{.spec.containers[0].readinessProbe}'

# Common issue:
readinessProbe:
  httpGet:
    path: /health
  initialDelaySeconds: 30   # Too long
  periodSeconds: 60         # Too infrequent
  timeoutSeconds: 30        # Too long
  failureThreshold: 3
```

**Impact:**
```
Pod starts at: 0s
Readiness probe starts at: 30s (initialDelay)
First check fails: 30s + 30s timeout = 60s
Second check fails: 120s
Third check succeeds: 180s

Pod available: 3 minutes after start!
```

**Solution:**
```yaml
readinessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 5   # Reduced
  periodSeconds: 5         # More frequent
  timeoutSeconds: 2        # Faster
  successThreshold: 1
  failureThreshold: 2

# Also optimize health endpoint
# Make it fast (<10ms)
```

---

**Hypothesis 7: Pod Affinity Spreading**

**Problem:** Pods scheduled on same node, resource contention.

**Investigation:**
```bash
# Check pod distribution
kubectl get pods -o wide | awk '{print $7}' | sort | uniq -c

# Output:
# 10 node-1  â† All pods on one node!
#  0 node-2
#  0 node-3

# Check node resources
kubectl top node node-1
# CPU: 95%, Memory: 90%  â† Overloaded!
```

**Solution:**
```yaml
# Spread pods across nodes
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app
spec:
  replicas: 6
  template:
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: myapp
              topologyKey: kubernetes.io/hostname
      
      # Also spread across AZs
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: myapp
```

---

**Hypothesis 8: Container Image Pull Time**

**Problem:** Large images take time to pull, delaying pod start.

**Investigation:**
```bash
# Check image pull time
kubectl describe pod <pod> | grep -A 5 "Events:"
# Look for: "Pulling image" ... "Successfully pulled image"
# Time difference = pull time

# Check image size
docker images | grep myapp
# If >1GB, that's the problem
```

**Solution:**
```dockerfile
# Optimize image (see Q12)
# Use image pull policy wisely
imagePullPolicy: IfNotPresent  # Don't always pull

# Use image cache (warm nodes)
# DaemonSet to pre-pull images
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: image-puller
spec:
  template:
    spec:
      initContainers:
      - name: puller
        image: myapp:latest
        command: ['sh', '-c', 'echo Image pulled']
      containers:
      - name: pause
        image: k8s.gcr.io/pause:3.1
```

---

**Complete Performance Checklist:**

```yaml
âœ“ DNS resolution (ndots, caching)
âœ“ Service mesh overhead (resource limits, disable if not needed)
âœ“ kube-proxy mode (iptables vs IPVS)
âœ“ Resource limits (CPU throttling)
âœ“ Network policies (simplify, consolidate)
âœ“ Readiness probes (optimize timing)
âœ“ Pod distribution (anti-affinity, spreading)
âœ“ Image size (pull time)
âœ“ Connection pooling (reuse connections)
âœ“ Horizontal scaling (more pods if needed)

Monitoring:
âœ“ RED metrics (Rate, Errors, Duration)
âœ“ Resource utilization (CPU, memory, network)
âœ“ DNS query time
âœ“ Service mesh metrics
âœ“ kube-proxy metrics
âœ“ Distributed tracing (Jaeger, Zipkin)
```

**Real Example Resolution:**

```
Initial state:
- 2000ms p95 latency

Investigation findings:
- DNS (ndots:5): +300ms
- Service mesh (under-resourced sidecar): +500ms
- iptables mode (1000 services): +600ms
- CPU throttling: +400ms

Solutions applied:
1. Reduced ndots to 2: -250ms
2. Increased sidecar CPU: -450ms  
3. Switched to IPVS: -550ms
4. Increased CPU limits: -350ms

Final latency: 400ms p95
Still higher than VM (200ms) but acceptable
Additional 200ms due to container/orchestration overhead

Further optimization:
- Enabled connection pooling: -100ms
- Final: 300ms p95 (50% increase vs VMs, acceptable trade-off for K8s benefits)
```

**Key Takeaway:**
Kubernetes adds some overhead (50-100ms typical). 10x degradation indicates misconfiguration, not inherent limitation. Systematic diagnosis and optimization can achieve near-VM performance."

---

## FINAL INTERVIEW TIPS

**Demonstrating Learning Mindset:**
- "I haven't worked with X, but here's how I'd approach learning it..."
- Share a recent technology you learned
- Discuss how you stay current (blogs, conferences, certifications)
- Example: "When I needed to learn Kubernetes, I set up a home lab, completed CKA certification, and contributed to an open-source project."

**Communication:**
- Explain technical concepts clearly
- Use diagrams when helpful
- Ask clarifying questions
- Admit when you don't know something

**Problem-Solving:**
- Think out loud
- Break down complex problems
- Consider trade-offs
- Discuss alternatives

**Production Mindset:**
- Security-first approach
- Monitoring and observability
- Documentation
- Cost awareness
- Team collaboration

**Good Luck with Your Interview!** ğŸš€